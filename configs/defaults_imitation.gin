include "configs/defaults.gin"

# Defaults common to all environments for imitation learning
load_policy.n_experts=1
train_and_plot.policy_dir="expert_models"
init_trainer.use_random_expert = False
init_trainer.num_vec = 8  # NOTE: changing this also changes the effective nsteps!

init_trainer.reward_kwargs = {
  'theta_units': [32, 32],
  'phi_units': [32, 32],
}
