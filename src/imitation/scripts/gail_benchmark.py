import os.path as osp
from typing import Any, Dict, Sequence

from imitation.scripts.config.gail_benchmark import gail_benchmark_ex
from imitation.scripts.train import train_ex

import sacred


@gail_benchmark_ex.main
def gail_benchmark(
  _seed: int,
  config_updates_list: Sequence[Dict[str, Any]],
  log_dir: str = "",
  train_ex_named_configs: Sequence[str] = (),
) -> Dict[tuple, Dict[str, float]]:
  """Run all the benchmarks from the GAIL paper.
  Params:
      _seed: The random seed. Automatically generated by Sacred.
      config_updates_list: List of `config_update` dictionaries for `train_ex`.
          Each `config_update` in `config_updates_list` starts a different run
          of `train_ex`, and results in a different datapoint for the return
          of this function.
      log_dir: Currently unused.
      train_ex_named_configs: List of `named_configs` for `train_ex`. This same
          list of `named_configs` is passed into every run of `train_ex`.
  Returns:
      A dictionary mapping `tuple(config_updates.items())` to a dictionary
      containing the "mean" and "std_err" of episode return (same as the results
      of `imitation.scripts.train.`).
  """
  all_results = {}
  for config_updates in config_updates_list:
    # TODO(shwang): This seems embarassingly parallellizable. (Ray later?)
    config_updates["seed"] = _seed
    run = train_ex.run(config_updates=config_updates,
                       named_configs=train_ex_named_configs)
    key = tuple(config_updates.items())
    all_results[key] = run.results
  return all_results


if __name__ == "__main__":
  observer = sacred.FileStorageObserver.create(
      osp.join('output', 'sacred', 'gail_benchmark'))
  gail_benchmark_ex.observers.append(observer)
  gail_benchmark_ex.run_commandline()
